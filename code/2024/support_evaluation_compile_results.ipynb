{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/97 [00:00<00:05, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IITD-IRL.zeph_rag_mistral_expansion_rrf_5.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_straight_ht.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_reverse.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_reverse_ht.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/97 [00:00<00:04, 18.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IITD-IRL.zeph_rag_mistral_expansion_rrf_10.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_straight_ht.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_reverse.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_reverse_ht.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_straight.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/97 [00:00<00:04, 19.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_straight_ht.jsonl\n",
      "Writing to file:  ldisnu.ragnarok.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_70b_filtered_meta-llama-Meta-Llama-3.1-70B-Instruct_llm_based_attribution_trec_rag_few_shots.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_straight.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_straight_ht.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 17/97 [00:00<00:04, 18.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  ielab.ielab_custom_baseline_blender_70b_filtered_meta-llama-Meta-Llama-3.1-70B-Instruct_ad_hoc_attribution.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_8b_filtered_meta-llama-Meta-Llama-3.1-8B-Instruct_ad_hoc_attribution.jsonl\n",
      "Writing to file:  ncsu-las.LAS-splade-mxbai-rrf-mmr8-rag24test-doc-multistep.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_reverse.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 23/97 [00:01<00:03, 22.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  ielab.ielab_custom_baseline_meta-llama-Meta-Llama-3.1-8B-Instruct_llm_based_attribution_no_trec_rag_few_shots.jsonl\n",
      "Writing to file:  IITD-IRL.zeph_test_rag_rrf_raw_query.jsonl\n",
      "Writing to file:  IITD-IRL.zeph_rag_mistral_expansion_rrf_15.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_straight.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_straight.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 29/97 [00:01<00:02, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  buw.buw_3.jsonl\n",
      "Writing to file:  buw.oneshot_post_sentenced.jsonl\n",
      "Writing to file:  IRIT.ISIR-IRIT-zephyr_query_gen.jsonl\n",
      "Writing to file:  IRIT.ISIR-IRIT-zephyr_sprompt_3p.jsonl\n",
      "Writing to file:  uog-tht.uog-tht.jsonl\n",
      "Writing to file:  buw.buw_1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 32/97 [00:01<00:02, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IRIT.ISIR-IRIT-zephyr_query_gen_3p.jsonl\n",
      "Writing to file:  InfoLab.bge-queryAgm.jsonl\n",
      "Writing to file:  gpt-4o_InfoLab.bm25-ro-defl.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_70b_filtered_meta-llama-Meta-Llama-3.1-70B-Instruct_llm_based_attribution_trec_rag_few_shots.jsonl\n",
      "Writing to file:  InfoLab.bge-AnsAI.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 38/97 [00:01<00:02, 22.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IITD-IRL.zeph_rag_mistral_expansion_rrf_20.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_reverse.jsonl\n",
      "Writing to file:  ncsu-las.LAS-enn-mmr8-rag24test.jsonl\n",
      "Writing to file:  WaterlooClarke.UWCgarag.jsonl\n",
      "Writing to file:  ncsu-las.LAS-splade-mxbai-rrf-mmr8-rag24test.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 44/97 [00:02<00:02, 21.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  webis.webis-reuserag-promptedreuse-k10.jsonl\n",
      "Writing to file:  Ruc01.Ruc01.jsonl\n",
      "Writing to file:  buw.buw_5.jsonl\n",
      "Writing to file:  InfoLab.bge-ranker.jsonl\n",
      "Writing to file:  IRIT.ISIR-IRIT-zephyr_p2.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 47/97 [00:02<00:02, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  citi.academia sinica.jsonl\n",
      "Writing to file:  buw.buw.jsonl\n",
      "Writing to file:  citi.academia sinica.jsonl\n",
      "Writing to file:  citi.academia sinica.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 53/97 [00:02<00:02, 19.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  citi.academia sinica.jsonl\n",
      "Writing to file:  ii_research.iiresearch-bm25-top10-llama3-8b-instruct.jsonl\n",
      "Writing to file:  citi.academia sinica.jsonl\n",
      "Writing to file:  WaterlooClarke.UWCrag.jsonl\n",
      "Writing to file:  citi.academia sinica.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 56/97 [00:02<00:02, 19.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  neu.neu.jsonl\n",
      "Writing to file:  neu.neu.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_8b_meta-llama-Meta-Llama-3.1-8B-Instruct_llm_based_attribution_no_trec_rag_few_shots.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_8b_filtered_meta-llama-Meta-Llama-3.1-8B-Instruct_ad_hoc_attribution.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 61/97 [00:02<00:01, 21.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_reverse_ht.jsonl\n",
      "Writing to file:  webis.webis-taskrag-zephyr-gpt4omini-k10.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_reverse_ht.jsonl\n",
      "Writing to file:  webis.webis-manual.jsonl\n",
      "Writing to file:  webis.webis-taskrag-zephyr-llama31-k10.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_8b_filtered_meta-llama-Meta-Llama-3.1-8B-Instruct_llm_based_attribution_no_trec_rag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 67/97 [00:03<00:01, 22.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  uog-tht.uog-tht.jsonl\n",
      "Writing to file:  SGU.Sai Gon University.jsonl\n",
      "Writing to file:  uog-tht.uog-tht.jsonl\n",
      "Writing to file:  ldisnu.ragnarok.jsonl\n",
      "Writing to file:  ldisnu.ragnarok.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 70/97 [00:03<00:01, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  webis.webis-taskrag-zephyr-gpt4omini-k20.jsonl\n",
      "Writing to file:  citi.academia sinica.jsonl\n",
      "Writing to file:  IITD-IRL.zeph_test_rag_rrf_expand_query.jsonl\n",
      "Writing to file:  ncsu-las.LAS-splade-mxbai-rrf-occams_segment_selection_50-titleraggy_test.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 76/97 [00:03<00:01, 19.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  ldisnu.ragnarok.jsonl\n",
      "Writing to file:  coordinators.baseline_frag_rag24.test_command-r-plus_top20.jsonl\n",
      "Writing to file:  softbank-meisei.ragtask-bm25-rank_zephyr-gpt4o-llama70b.jsonl\n",
      "Writing to file:  ncsu-las.LAS-splade-mxbai-mmr8-rag24test.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 82/97 [00:03<00:00, 22.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IITD-IRL.zeph_test.rag24.rrf.jsonl\n",
      "Writing to file:  TREMA-UNH.baseline.jsonl\n",
      "Writing to file:  ielab.ielab_custom_baseline_blender_8b_filtered_meta-llama-Meta-Llama-3.1-8B-Instruct_llm_based_attribution_no_trec_rag_few_shots.jsonl\n",
      "Writing to file:  webis.webis-reuserag-promptedreuse-clustered.jsonl\n",
      "Writing to file:  gpt-4o_coordinators.coordinators.all_nuggets.jsonl\n",
      "Writing to file:  gpt-4o_coordinators.coordinators.anserini_bm25.rag24.test_top1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 87/97 [00:04<00:00, 25.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  gpt-4o_coordinators.coordinators.fs4_bm25+rocchio_snowael_snowaem_gtel+monot5_rrf+rz_rrf.rag24.test_top1.jsonl\n",
      "Writing to file:  coordinators.coordinators.all_nuggets.jsonl\n",
      "Writing to file:  coordinators.coordinators.all_nuggets.jsonl\n",
      "Writing to file:  coordinators.coordinators.fs4_bm25+rocchio_snowael_snowaem_gtel+monot5_rrf+rz_rrf.rag24.test_top1.jsonl\n",
      "Writing to file:  InfoLab.UdInfo-RAG-bge-t.jsonl.jsonl\n",
      "Writing to file:  h2oloo.listgalore_gpt4o_ragnarokv4nocite_top20.jsonl\n",
      "Writing to file:  h2oloo.listgalore_l31-70b_ragnarokv4nocite_top20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 94/97 [00:04<00:00, 25.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  coordinators.baseline_frag_rag24.test_gpt-4o_top20.jsonl\n",
      "Writing to file:  WaterlooClarke.UWCrag_stepbystep.jsonl\n",
      "Writing to file:  softbank-meisei.rag_bm25-colbert_faiss-gpt4o-llama70b.jsonl\n",
      "Writing to file:  coordinators.coordinators.anserini_bm25.rag24.test_top1.jsonl\n",
      "Writing to file:  InfoLab.UdInfo-RAG-bgeQueryAgm-t.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [00:04<00:00, 21.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  InfoLab.UdInfo-RAG-bgeAnsAi-t.jsonl\n",
      "Writing to file:  h2oloo.listgalore_gpt4o_ragnarokv4_top20.jsonl\n",
      "Writing to file:  h2oloo.listgalore_l31-70b_ragnarokv4_top20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/53 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_0.5_100_301_p2.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_straight_ht_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/53 [00:00<00:02, 23.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_0.25_100_301_p1.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_0.5_100_301_p3.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_reverse_ht_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 6/53 [00:00<00:02, 22.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  webis.webis-taskrag-gpt4omini-k20.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_20_0.5_100_301_p1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 9/53 [00:00<00:01, 25.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  CIR.cir_gpt-4o-mini_Jaccard_50_1.0_100_301_p0.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_0.5_100_301_p1.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_straight_ht_ag.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_reverse_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 12/53 [00:00<00:01, 26.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_straight_ht_ag.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_straight_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 15/53 [00:00<00:01, 25.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  webis.webis-reuserag-baseline-promptedreuse-clustered.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_straight_ag.jsonl\n",
      "Writing to file:  KML.cmd_plus_prompt.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_gpt35_expansion_rrf_20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 18/53 [00:00<00:01, 21.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_reverse_ag.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_reverse_ht_ag.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_straight_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 21/53 [00:00<00:01, 20.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p2_straight_ht_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 24/53 [00:01<00:01, 20.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_straight_ag.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_no_reranking_50_0.5_100_301_p1.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_mistral_expansion_rrf_20.jsonl\n",
      "Writing to file:  webis.webis-taskrag-gpt4omini-k10.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_gpt35_expansion_rrf_7.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 30/53 [00:01<00:00, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  IIIA-UNIPD.iiia_standard_p1_reverse_ag.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_Jaccard_50_0.5_100_301_p0.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_mistral_expansion_rrf_7.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_mistral_expansion_rrf_15.jsonl\n",
      "Writing to file:  IITD-IRL.ag_rag_gpt35_expansion_rrf_15.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 33/53 [00:01<00:00, 22.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  KML.chatgpt_4_mini.jsonl\n",
      "Writing to file:  uis-iai.ginger.jsonl\n",
      "Writing to file:  TREMA-UNH.generated_pormpt_based_sort_flag_True_ragnarbm25.jsonl\n",
      "Writing to file:  TREMA-UNH.generated_rule_based_sort_flag_False_ragnarbm25.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 36/53 [00:01<00:00, 23.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  coordinators.baseline_rag24.test_command-r-plus_top20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 39/53 [00:01<00:00, 23.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  softbank-meisei.agtask-bm25-colbert_faiss-gpt4o-llama70b.jsonl\n",
      "Writing to file:  uis-iai.baseline_top_5.jsonl\n",
      "Writing to file:  ldisnu.ragnarok.jsonl\n",
      "Writing to file:  uis-iai.ginger-fluency_top_5.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 42/53 [00:01<00:00, 23.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  uis-iai.ginger-fluency_top_20.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_reverse_ag.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 45/53 [00:01<00:00, 22.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  webis.webis-reuserag-baseline-promptedreuse-k10.jsonl\n",
      "Writing to file:  uis-iai.ginger-fluency_top_10.jsonl\n",
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_0.75_100_301_p1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 48/53 [00:02<00:00, 24.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  CIR.cir_gpt-4o-mini_Cosine_50_1.0_100_301_p1.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p1_reverse_ht_ag.jsonl\n",
      "Writing to file:  IIIA-UNIPD.iiia_dedup_p2_reverse_ht_ag.jsonl\n",
      "Writing to file:  InfoLab.ag-v1.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 51/53 [00:02<00:00, 19.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  KML.chatgpt_4_mini.jsonl\n",
      "Writing to file:  InfoLab.AGv2.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 53/53 [00:02<00:00, 22.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to file:  coordinators.baseline_rag24.test_gpt-4o_top20.jsonl\n",
      "Writing to file:  coordinators.baseline_rag24.test_l31_70b_instruct_top20.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os, csv\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "DIR=\"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/results/support\"\n",
    "OUTPUT_DIR=\"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/competition/results/llm_pred_all_301_topics\"\n",
    "RESULTS_DIR = [f\"{DIR}/gen/pairwise\", f\"{DIR}/auggen/pairwise\"]\n",
    "tasks = [\"gen\", \"auggen\"]\n",
    "SCORES_WEIGHTED = {\"NS\": 0, \"PS\": 0.5, \"FS\": 1.0}\n",
    "SCORES_HARD = {\"NS\": 0, \"PS\": 0, \"FS\": 1.0}\n",
    "\n",
    "for idx, results_dir in enumerate(RESULTS_DIR):\n",
    "    task = tasks[idx]\n",
    "    input_filepaths = os.listdir(results_dir)\n",
    "    # Remove the markdown files\n",
    "    input_filepaths = [input_filepath for input_filepath in input_filepaths if not input_filepath.endswith(\".md\")]\n",
    "    for input_filepath in tqdm(input_filepaths):\n",
    "        avg_weighted_precision, avg_weighted_recall, avg_hard_precision, avg_hard_recall, avg_sentences = 0, 0, 0, 0, 0\n",
    "        with open(os.path.join(results_dir, input_filepath), 'r') as fin:\n",
    "            results = {}\n",
    "            for line in fin:\n",
    "                weighted_precision, weighted_recall, hard_precision, hard_recall, sentences = 0, 0, 0, 0, 0\n",
    "                data = json.loads(line)\n",
    "                topic_id = data['topic_id']\n",
    "                group_name = input_filepath.split(\".\")[0]\n",
    "                os.makedirs(f\"{OUTPUT_DIR}/{task}/merged\", exist_ok=True)\n",
    "                assert len(data['answer']) == len(data['support_eval'])\n",
    "                sentences = len(data['support_eval'])\n",
    "                scores = []\n",
    "                for row in data['support_eval']:\n",
    "                    if len(row['eval_scores']) > 0:\n",
    "                        if row['eval_scores'][0] in [\"NS\", \"PS\", \"FS\"]:\n",
    "                            scores.append(row['eval_scores'][0])\n",
    "                \n",
    "                if len(scores) > 0:\n",
    "                    weighted_precision = sum([SCORES_WEIGHTED[score] for score in scores]) / len(scores)\n",
    "                    hard_precision = sum([SCORES_HARD[score] for score in scores]) / len(scores)\n",
    "                \n",
    "                weighted_recall = sum([SCORES_WEIGHTED[score] for score in scores]) / sentences\n",
    "                hard_recall = sum([SCORES_HARD[score] for score in scores]) / sentences\n",
    "                avg_weighted_precision += weighted_precision\n",
    "                avg_hard_precision += hard_precision\n",
    "                avg_weighted_recall += weighted_recall\n",
    "                avg_hard_recall += hard_recall\n",
    "                avg_sentences += sentences\n",
    "                results[topic_id] = {\n",
    "                    \"weighted_precision\": weighted_precision,\n",
    "                    \"weighted_recall\": weighted_recall,\n",
    "                    \"hard_precision\": hard_precision,\n",
    "                    \"hard_recall\": hard_recall,\n",
    "                    \"sentences\": sentences\n",
    "                }\n",
    "            output_filepath = f\"{OUTPUT_DIR}/{task}/merged/{input_filepath}\"\n",
    "            print(\"Writing to file: \", input_filepath)\n",
    "            with open(output_filepath, 'w') as fout:\n",
    "                for topic_id, result in results.items():\n",
    "                    fout.write(json.dumps({\n",
    "                        \"topic_id\": topic_id,\n",
    "                        \"weighted_precision\": result[\"weighted_precision\"],\n",
    "                        \"weighted_recall\": result[\"weighted_recall\"],\n",
    "                        \"hard_precision\": result[\"hard_precision\"],\n",
    "                        \"hard_recall\": result[\"hard_recall\"],\n",
    "                        \"sentences\": result[\"sentences\"]\n",
    "                    }) + \"\\n\")\n",
    "                \n",
    "                fout.write(json.dumps({\n",
    "                    \"topic_id\": \"all\",\n",
    "                    \"weighted_precision\": avg_weighted_precision / 301,\n",
    "                    \"weighted_recall\": avg_weighted_recall / 301,\n",
    "                    \"hard_precision\": avg_hard_precision / 301,\n",
    "                    \"hard_recall\": avg_hard_recall / 301,\n",
    "                    \"sentences\": avg_sentences / 301,\n",
    "                }) + \"\\n\")\n",
    "                    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, csv\n",
    "from tqdm.autonotebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DIR=\"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/results/support\"\n",
    "RESULTS_DIR = [f\"{DIR}/rag-track/pairwise\", f\"{DIR}/ag-track/pairwise\"]\n",
    "\n",
    "for idx, results_dir in enumerate(RESULTS_DIR):\n",
    "\n",
    "    topic_results = {}\n",
    "\n",
    "    input_filepaths = os.listdir(results_dir)\n",
    "    # Remove the markdown files\n",
    "    input_filepaths = [input_filepath for input_filepath in input_filepaths if not input_filepath.endswith(\".md\")]\n",
    "    for input_filepath in tqdm(input_filepaths, desc=f\"Processing {results_dir}\", total=len(input_filepaths)):\n",
    "        with open(os.path.join(results_dir, input_filepath), 'r') as fin:\n",
    "            for line in fin:\n",
    "                data = json.loads(line)\n",
    "                topic_id = data[\"topic_id\"]\n",
    "                if topic_id not in topic_results:\n",
    "                    topic_results[topic_id] = {\n",
    "                        \"topic\": data[\"topic\"],\n",
    "                        \"num_sentences\": 0,\n",
    "                        \"avg_response_length\": 0,\n",
    "                        \"full_support_count\": 0,\n",
    "                        \"partial_support_count\": 0,\n",
    "                        \"no_support_count\": 0,\n",
    "                        \"support_score\": 0\n",
    "                    }\n",
    "                \n",
    "                support_scores = []\n",
    "                for row in data['support_eval']:\n",
    "                    scores_dict = {\"NS\": 0, \"PS\": 0.5, \"FS\": 1.0}\n",
    "                    if len(row['eval_scores']) == 0 or None in row['eval_scores']:\n",
    "                        support_scores.append(0)\n",
    "                    else:\n",
    "                        support_scores.append(sum([scores_dict[score] for score in row['eval_scores']]) / len(row['eval_scores']))\n",
    "\n",
    "                    for score in row['eval_scores']:\n",
    "                        if score == \"FS\":\n",
    "                            topic_results[topic_id][\"full_support_count\"] += 1\n",
    "                        elif score == \"PS\":\n",
    "                            topic_results[topic_id][\"partial_support_count\"] += 1\n",
    "                        elif score == \"NS\":\n",
    "                            topic_results[topic_id][\"no_support_count\"] += 1\n",
    "\n",
    "                topic_results[topic_id][\"avg_response_length\"] += data['response_length']\n",
    "                topic_results[topic_id][\"num_sentences\"] += len(data['support_eval'])\n",
    "                topic_results[topic_id][\"support_score\"] += sum(support_scores) / len(support_scores)\n",
    "                \n",
    "    for topic_id in topic_results:\n",
    "        topic_results[topic_id][\"avg_response_length\"] /= len(input_filepaths)\n",
    "        topic_results[topic_id][\"num_sentences\"] /= len(input_filepaths)\n",
    "        topic_results[topic_id][\"support_score\"] /= len(input_filepaths)\n",
    "    \n",
    "    # printing the topicwise results as a scatterplot with support score on x-axis and avg. response length on y-axis\n",
    "    RESULTS_DIR_OUTPUT = \"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/summary/support\"\n",
    "    title = \"RAG Track\" if idx == 0 else \"AG Track\"\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.scatter(x=[topic_results[topic_id][\"avg_response_length\"] for topic_id in topic_results], y=[topic_results[topic_id][\"support_score\"] for topic_id in topic_results])\n",
    "    plt.ylabel(\"Support Score\", fontsize=14)\n",
    "    plt.xlabel(\"Avg. Response Length\", fontsize=14)\n",
    "    plt.title(\"Topic wise statistics in {}\".format(title), fontsize=16)\n",
    "    plt.legend([\"Topics\"], loc='upper right')\n",
    "    plt.savefig(f\"{RESULTS_DIR_OUTPUT}/topicwise_support_score_vs_avg_response_length_{title.lower().replace(' ', '_')}.png\")\n",
    "\n",
    "    output_filepath = \"topicwise_support_results_rag_track.csv\" if idx == 0 else \"topicwise_support_results_ag_track.csv\"\n",
    "    # sort topics based on highest to lowest support score\n",
    "    topic_results = {k: v for k, v in sorted(topic_results.items(), key=lambda item: item[1][\"support_score\"], reverse=True)}\n",
    "    \n",
    "    with open(f\"{RESULTS_DIR_OUTPUT}/{output_filepath}\", 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([\"Topic ID\", \"Topic\", \"Avg. #Sentences\", \"Avg. Response Length\", \"Support Score\", \"FS Count\", \"PS Count\", \"NS Count\"])\n",
    "        for topic_id in topic_results:\n",
    "            writer.writerow([\n",
    "                topic_id, \n",
    "                topic_results[topic_id][\"topic\"], \n",
    "                round(topic_results[topic_id][\"num_sentences\"], 2), \n",
    "                round(topic_results[topic_id][\"avg_response_length\"], 2), \n",
    "                round(topic_results[topic_id][\"support_score\"], 2), \n",
    "                round(topic_results[topic_id][\"full_support_count\"], 2), \n",
    "                round(topic_results[topic_id][\"partial_support_count\"], 2), \n",
    "                round(topic_results[topic_id][\"no_support_count\"], 2)\n",
    "                ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, csv\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "DIR=\"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/results/support\"\n",
    "RESULTS_DIR = [f\"{DIR}/rag-track/pairwise\", f\"{DIR}/ag-track/pairwise\"]\n",
    "\n",
    "for idx, results_dir in enumerate(RESULTS_DIR):\n",
    "    participant_results = {}\n",
    "    input_filepaths = os.listdir(results_dir)\n",
    "    # Remove the markdown files\n",
    "    input_filepaths = [input_filepath for input_filepath in input_filepaths if not input_filepath.endswith(\".md\")]\n",
    "    for input_filepath in tqdm(input_filepaths, desc=f\"Processing {results_dir}\", total=len(input_filepaths)):\n",
    "        with open(os.path.join(results_dir, input_filepath), 'r') as fin:\n",
    "            total_topics = 0\n",
    "            \n",
    "            for line in fin:\n",
    "                total_topics += 1\n",
    "                data = json.loads(line)\n",
    "                topic_id = data[\"topic_id\"]\n",
    "\n",
    "                if input_filepath not in participant_results:\n",
    "                    participant_results[input_filepath] = {\n",
    "                        \"run_id\": data[\"run_id\"],\n",
    "                        \"num_sentences\": 0,\n",
    "                        \"avg_response_length\": 0,\n",
    "                        \"full_support_count\": 0,\n",
    "                        \"partial_support_count\": 0,\n",
    "                        \"no_support_count\": 0,\n",
    "                        \"support_score\": 0\n",
    "                    }\n",
    "                \n",
    "                support_scores = []\n",
    "                for row in data['support_eval']:\n",
    "                    scores_dict = {\"NS\": 0, \"PS\": 0.5, \"FS\": 1.0}\n",
    "                    if len(row['eval_scores']) == 0 or None in row['eval_scores']:\n",
    "                        support_scores.append(0)\n",
    "                    else:\n",
    "                        support_scores.append(sum([scores_dict[score] for score in row['eval_scores']]) / len(row['eval_scores']))\n",
    "\n",
    "                    for score in row['eval_scores']:\n",
    "                        if score == \"FS\":\n",
    "                            participant_results[input_filepath][\"full_support_count\"] += 1\n",
    "                        elif score == \"PS\":\n",
    "                            participant_results[input_filepath][\"partial_support_count\"] += 1\n",
    "                        elif score == \"NS\":\n",
    "                            participant_results[input_filepath][\"no_support_count\"] += 1\n",
    "\n",
    "                participant_results[input_filepath][\"avg_response_length\"] += data['response_length']\n",
    "                participant_results[input_filepath][\"num_sentences\"] += len(data['support_eval'])\n",
    "                participant_results[input_filepath][\"support_score\"] += sum(support_scores) / len(support_scores)\n",
    "                \n",
    "        participant_results[input_filepath][\"avg_response_length\"] /= total_topics\n",
    "        participant_results[input_filepath][\"num_sentences\"] /= total_topics\n",
    "        participant_results[input_filepath][\"support_score\"] /= total_topics\n",
    "    \n",
    "    # printing the topicwise results\n",
    "    RESULTS_DIR_OUTPUT = \"/store/scratch/n3thakur/trec-rag-2024/trec2024-rag/support_eval/summary/support\"\n",
    "    title = \"RAG Track\" if idx == 0 else \"AG Track\"\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.scatter(x=[participant_results[input_filepath][\"avg_response_length\"] for input_filepath in input_filepaths], y=[participant_results[input_filepath][\"support_score\"] for input_filepath in input_filepaths])\n",
    "    plt.ylabel(\"Support Score\", fontsize=14)\n",
    "    plt.xlabel(\"Avg. Response Length\", fontsize=14)\n",
    "    plt.title(\"Participant wise statistics in {}\".format(title), fontsize=16)\n",
    "    plt.legend([\"Runs\"], loc='upper right')\n",
    "    plt.savefig(f\"{RESULTS_DIR_OUTPUT}/participantwise_support_score_vs_avg_response_length_{title.lower().replace(' ', '_')}.png\")\n",
    "\n",
    "\n",
    "    output_filepath = \"participantwise_support_results_rag_track.csv\" if idx == 0 else \"participantwise_support_results_ag_track.csv\"\n",
    "\n",
    "    # sort participant results based on highest to lowest support score\n",
    "    participant_results = {k: v for k, v in sorted(participant_results.items(), key=lambda item: item[1][\"support_score\"], reverse=True)}\n",
    "\n",
    "    with open(f\"{RESULTS_DIR_OUTPUT}/{output_filepath}\", 'w') as fout:\n",
    "        writer = csv.writer(fout, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        writer.writerow([\"File Name\", \"Run ID\", \"Avg. #Sentences\", \"Avg. Response Length\", \"Support Score\", \"FS Count\", \"PS Count\", \"NS Count\"])\n",
    "        for input_filepath in participant_results:\n",
    "            writer.writerow([\n",
    "                input_filepath.replace(\".jsonl\", \"\"),\n",
    "                participant_results[input_filepath][\"run_id\"], \n",
    "                round(participant_results[input_filepath][\"num_sentences\"], 2), \n",
    "                round(participant_results[input_filepath][\"avg_response_length\"], 2), \n",
    "                round(participant_results[input_filepath][\"support_score\"], 2), \n",
    "                round(participant_results[input_filepath][\"full_support_count\"], 2), \n",
    "                round(participant_results[input_filepath][\"partial_support_count\"], 2), \n",
    "                round(participant_results[input_filepath][\"no_support_count\"], 2)\n",
    "                ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unsloth_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
